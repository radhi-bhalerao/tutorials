{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyAFQ tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "pyAFQ is an open source tractometry software that allows users to understand white matter connections between distant cortical regions using diffusion weighted MRI. This tutorial is a step step process for imaging researchers to use to familiarize themselves with the basics of pyAFQ and it's coding requirements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing environments \n",
    "\n",
    "To run this tutorial, open a terminal and cd to the bin folder and run the following command: source activate venv. This will activate a virtual environment called venv and will allow you to import the libraries needed to run the code. Also ensure that the kernel of the Jupyter Notebook is also set to pyAFQ_tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libaries \n",
    "import os \n",
    "import os.path as open\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from AFQ.api.group import GroupAFQ\n",
    "import AFQ.data.fetch as afd \n",
    "import bids\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the example dataset \n",
    "#Note you only need to run this once! \n",
    "#Example data gathered from Stanford HARDI dataset https://purl.stanford.edu/ng782rw8378 \n",
    "afd.organize_stanford_data(clear_previous_afq=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group AFQ object \n",
    "\n",
    "pyAFQ is a customizable tool and a good starting place is using the GroupAFQ object. Initializing this object allows the user to set many different input and processing options for the pipeline as listed below:  \n",
    "\n",
    "**Inputs of GroupAFQ Object**  \n",
    "\n",
    "bids_path : str  \n",
    ">The path to preprocessed diffusion data organized in a BIDS dataset. This should contain a BIDS derivative dataset with preprocessed dwi/bvals/bvecs.  \n",
    "\n",
    "bids_filters : dict  \n",
    "\n",
    ">Filter to pass to bids_layout.get when finding DWI files. Default: {\"suffix\": \"dwi\"}  \n",
    "\n",
    "preproc_pipeline : str, optional.  \n",
    "\n",
    ">The name of the pipeline used to preprocess the DWI data. Default: \"all\".  \n",
    "\n",
    "participant_labels : list or None, optional  \n",
    "\n",
    ">List of participant labels (subject IDs) to perform processing on. If None, all subjects are used. Default: None  \n",
    "\n",
    "output_dir : str or None, optional  \n",
    "\n",
    ">Path to output directory. If None, outputs are put in a AFQ pipeline folder in the derivatives folder of the BIDS directory. pyAFQ will use existing derivatives from the output directory if they exist, instead of recalculating them (this means you need to clear the output folder if you want to recalculate a derivative). Default: None  \n",
    "\n",
    "parallel_params : dict, optional  \n",
    "\n",
    ">Parameters to pass to paramap in AFQ.utils.parallel, to parallelize computations across subjects and sessions. Set \"n_jobs\" to -1 to automatically parallelize as the number of cpus. Here is an example for how to do multiprocessing with 4 cpus: {\"n_jobs\": 4, \"engine\": \"joblib\", \"backend\": \"loky\"} Default: {\"engine\": \"serial\"}  \n",
    "\n",
    "bids_layout_kwargs: dict, optional  \n",
    "\n",
    ">Additional arguments to give to BIDSLayout from pybids. For large datasets, try: {\"validate\": False, \"index_metadata\": False}. Default: {}  \n",
    "\n",
    "kwargs : additional optional parameters  \n",
    ">You can set additional parameters for any step of the process. See usage/kwargs for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize GroupAFQ object\n",
    "myafq = GroupAFQ(\n",
    "    bids_path=open.join(afd.afq_home, 'stanford_hardi'),\n",
    "    preproc_pipeline='vistasoft',\n",
    "    viz_backend_spec='plotly_no_gif')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export function \n",
    "\n",
    "After initializing the GroupAFQ object, use the function export with the correct input string to get the output you would like from pyAFQ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myafq.export(); #Allows you to see all options of input for the function export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = myafq.export('profiles')['01']\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myafq.export('indiv_bundles_figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_fname = myafq.export(\"dti_fa\")[\"01\"]\n",
    "print(FA_fname)\n",
    "FA_img = nib.load(FA_fname)\n",
    "FA = FA_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.matshow(FA[:, :, FA.shape[-1] // 2], cmap='viridis')\n",
    "ax.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
